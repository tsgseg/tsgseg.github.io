<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}

	h1 {
		font-size:32px;
		font-weight:300;
	}

	.disclaimerbox {
		background-color: #eee;
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}

	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}

	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		15px 15px 0 0px #fff, /* The fourth layer */
		15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		20px 20px 0 0px #fff, /* The fifth layer */
		20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		25px 25px 0 0px #fff, /* The fifth layer */
		25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}

	.vert-cent {
		position: relative;
		top: 50%;
		transform: translateY(-50%);
	}

	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>

<html>
<head>
	<title>TSG-Seg</title>
	<meta property="og:image" content="Path to my teaser.png"/> <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/ if you update and want to force Facebook to rescrape. -->
	<meta property="og:title" content="TSG-Seg: Temporal-Selective Guidance for Semi-Supervised Semantic Segmentation of 3D LiDAR Point Clouds" />
	<meta property="og:description" content="Paper description." />

	<!-- Get from Google Analytics -->
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src=""></script>
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'UA-75863369-6');
	</script>
</head>

<body>
	<br>
	<center>
		<span style="font-size:30px"><b>TSG-Seg: Temporal-Selective Guidance for Semi-Supervised Semantic Segmentation of 3D LiDAR Point Clouds</b></span>
		<table align=center width=600px>
			<table align=center width=600px>
				<tr>
					<td align=center width=100px>
						<center>
							<span style="font-size:20px">Weihao Xuan<sup>1</sup></span>
						</center>
					</td>
					<td align=center width=100px>
						<center>
							<span style="font-size:20px">Heli Qi<sup>2</sup></span>
						</center>
					</td>
					<td align=center width=100px>
						<center>
							<span style="font-size:20px">Aoran Xiao<sup>3</sup></span>
						</center>
					</td>
				</tr>
			</table>
			<table align=center width=350px>
				<td align=center width=200px>
					<span style="font-size:20px">Waseda University<sup>1</sup></span>
				</td>
			</table>
			<table align=center width=550px>
				<td align=center width=500px>
					<span style="font-size:20px">NARA Institute of Science and Technology<sup>2</sup></span>
				</td>
			</table>
			<table align=center width=450px>
				<td align=center width=300px>
					<span style="font-size:20px">Nanyang Technological University<sup>3</sup></span>
				</td>
			</table>
			<table align=center width=250px>
				<tr>
					<td align=center width=120px>
						<center>
							<span style="font-size:20px"><a href='https://www.sciencedirect.com/science/article/abs/pii/S0924271624002879'>[Paper]</a></span><br>
						</center>
					</td>
<!--					<td align=center width=120px>-->
<!--						<center>-->
<!--							<span style="font-size:20px">[Video]</span>-->
<!--						</center>-->
<!--					</td>-->
				</tr>
			</table>
		</table>
	</center>

	<hr>

	<table align=center width=850px>
		<center><h1><span style="font-size:24px">Abstract</span></h1></center>
		<tr>
			<td>
				LiDAR-based semantic scene understanding holds a pivotal role in various applications, including remote sensing and autonomous driving. However, the majority of LiDAR segmentation models rely on extensive and densely annotated training datasets, which is extremely laborious to annotate and hinder the widespread adoption of LiDAR systems. Semi-supervised learning (SSL) offers a promising solution by leveraging only a small amount of labeled data and a larger set of unlabeled data, aiming to train robust models with desired accuracy comparable to fully supervised learning. A typical pipeline of SSL involves the initial use of labeled data to train segmentation models, followed by the utilization of predictions generated from unlabeled data, which are used as pseudo-ground truths for model retraining. However, the scarcity of labeled data limits the capture of comprehensive representations, leading to the constraints of these pseudo-ground truths in reliability. We observed that objects captured by LiDAR sensors from varying perspectives showcase diverse data characteristics due to occlusions and distance variation, and LiDAR segmentation models trained with limited labels prove susceptible to these viewpoint disparities, resulting in inaccurately predicted pseudo-ground truths across viewpoints and the accumulation of retraining errors. To address this problem, we introduce the Temporal-Selective Guided Learning (TSG-Seg) framework. TSG-Seg explores temporal cues inherent in LiDAR frames to bridge the cross-viewpoint representations, fostering consistent and robust segmentation predictions across differing viewpoints. Specifically, we first establish point-wise correspondences across LiDAR frames with different time stamps through point registration. Subsequently, reliable point predictions are selected and propagated to points from adjacent views to the current view, serving as strong and refined supervision signals for subsequent model re-training to achieve better segmentation. Extensive experiments conducted on multiple datasets demonstrate the effectiveness of TSG-Seg, showing competitive performance and robustness in various settings ranging from data-limited to data-abundant scenarios.
			</td>
		</tr>
	</table>
	<br>

	<center>
		<table align=center width=850px>
			<tr>
				<td width=850px>
					<center>
						<img class="round" style="width:850px" src="src/illustration.png"/>
					</center>
				</td>
			</tr>
		</table>
	</center>


<!--	<center><h1>Talk</h1></center>-->
<!--	<p align="center">-->
<!--		<iframe width="660" height="395" src="https://www.youtube.com/embed/dQw4w9WgXcQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen align="center"></iframe>-->
<!--	</p>-->

<!--	<table align=center width=800px>-->
<!--		<br>-->
<!--		<tr>-->
<!--			<center>-->
<!--				<span style="font-size:28px"><a href=''>[Slides]</a>-->
<!--				</span>-->
<!--			</center>-->
<!--		</tr>-->
<!--	</table>-->
<!--	<hr>-->

<!--<table align=center width=850px>-->
<!--	<center><h1><span style="font-size:24px">Demo Video</span></h1></center>-->
<!--	<tr>-->
<!--		<center>-->
<!--        <iframe width="800" height="600" src="https://www.youtube.com/embed/h4soLIEZIYk?si=QqyCoKwEA-IFZ9ZE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>-->
<!--    </center>-->
<!--	</tr>-->
<!--</table>-->


	<table align=center width=850px>
		<center><h1><span style="font-size:24px">Citation</span></span></h1></center>
		<tr>
			<td>
				<pre>
		@article{xuan2024tsg,
			  title={TSG-Seg: Temporal-selective guidance for semi-supervised semantic segmentation of 3D LiDAR point clouds},
			  author={Xuan, Weihao and Qi, Heli and Xiao, Aoran},
			  journal={ISPRS Journal of Photogrammetry and Remote Sensing},
			  volume={216},
			  pages={217--228},
			  year={2024},
			  publisher={Elsevier}
			}
				</pre>
			</td>
		</tr>
	</table>
	<br>

<br>
</body>
</html>
